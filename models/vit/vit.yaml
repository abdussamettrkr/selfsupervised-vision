arch: 'vit_small' #'vit_tiny','vit_small','vit_base','xcit','deit_tiny','deit_small'
patch_size: 16    #VIT square patch sizes. Default 16
out_dim: 65536    #Dimensionality of the DINO head output, bigger valus for complex tax. Default 65536
norm_last_layer: True #Whether or not normilize the last layer of DINO head. Increases Training stability
momentum_teacher: 0.996 #Base EMA paramater used for teacher parameter uptade. The value increased to 1 during training with Cosine Schedule. Bigger value for smaller batch-size.
use_bn_in_head: False #Wheter or not use batch normilization in projection head. Default False
warmup_teacher_temp: 0.04 #Final value (after linear warmup)of the teacher temperature.
warmup_teacher_temp_epochs: 30 #Number of warmup epochs for the teacher temperature (Default: 30).
teacher_temp: 0.04 #Initial value for the teacher temperature
use_fp16: True
weight_decay: 0.04 #Initial value of the weight decay.
weight_decay_end: 0.4 
clip_grad: 3.0
epochs: 1000
freeze_last_layer: 1 #Number of epochs during which we keep the output layer fixed.
lr: 0.0005
warmup_epochs: 10
min_lr: 0.000001
optimizer: 'adamw'
drop_path_rate: 0.1 #stochastic depth rate
global_crops_scale: [0.4,1.] #Scale range of the cropped image before resizing, relatively to the origin image. Used for large global view cropping.
local_crops_number: 8
local_crops_scale: [0.05,0.4]
data_path: "/path/to/imagenet/train"
output_dir: "."
saveckp_freq: 20
seed: 41
num_workers: 10
